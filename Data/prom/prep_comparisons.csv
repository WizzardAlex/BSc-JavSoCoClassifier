classifier,setting_id,Feature rep.,settings,accuracy,macro_precision,macro_recall,weighted_precision,weighted_recall,macro_f1,weighted_f1,train_size,test_size,report_table
MaxEnt,s0,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk']]",0.8241469816272966,0.7234873237699658,0.7093431023508094,0.8202583622036731,0.8241469816272966,0.7060273489555435,0.8145807398018354,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.888889      0.985507     0.921951   
recall                    0.0          0.975610      1.000000     0.940299   
f1-score                  0.0          0.930233      0.992701     0.931034   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            1.000000              0.588235               0.662069   
recall               0.688889              0.344828               0.849558   
f1-score             0.815789              0.434783               0.744186   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.753623         0.711111  0.824147    0.723487   
recall               0.981132         0.603774  0.824147    0.709343   
f1-score             0.852459         0.653061  0.824147    0.706027   
support             53.000000       106.000000  0.824147  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.820258  
recall         0.824147  
f1-score       0.814581  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s0,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk']]",0.8018372703412073,0.7355251390782995,0.6932117477721498,0.8077045558082254,0.8018372703412073,0.7009575063255183,0.7953132673812828,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.166667          0.900000      1.000000     0.877451   
recall               0.222222          0.878049      0.985294     0.890547   
f1-score             0.190476          0.888889      0.992593     0.883951   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.956522              0.487179               0.675000   
recall               0.488889              0.327586               0.955752   
f1-score             0.647059              0.391753               0.791209   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.903846         0.653061  0.801837    0.735525   
recall               0.886792         0.603774  0.801837    0.693212   
f1-score             0.895238         0.627451  0.801837    0.700958   
support             53.000000       106.000000  0.801837  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.807705  
recall         0.801837  
f1-score       0.795313  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s0,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk']]",0.8044619422572179,0.7494633805818637,0.7168232046790975,0.8142987062627887,0.8044619422572179,0.7208692566702984,0.8015681054363162,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.428571          0.690909      0.992593     0.832487   
recall               0.333333          0.926829      0.985294     0.815920   
f1-score             0.375000          0.791667      0.988930     0.824121   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.551020              0.783784               0.814516   
recall               0.600000              0.500000               0.893805   
f1-score             0.574468              0.610526               0.852321   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.968750         0.682540  0.804462    0.749463   
recall               0.584906         0.811321  0.804462    0.716823   
f1-score             0.729412         0.741379  0.804462    0.720869   
support             53.000000       106.000000  0.804462  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.814299  
recall         0.804462  
f1-score       0.801568  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s0,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk']]",0.8241469816272966,0.8230209383264849,0.7786908059411789,0.8346899909177832,0.8241469816272966,0.7791997651747621,0.8239092376918177,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000           0.95122      0.950704     0.903030   
recall               0.333333           0.95122      0.992647     0.741294   
f1-score             0.500000           0.95122      0.971223     0.814208   
support              9.000000          41.00000    136.000000   201.000000   
Test                 9.000000          41.00000    136.000000   201.000000   
Train                1.000000           5.00000     15.000000    22.000000   
Total               10.000000          46.00000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.573770              0.701754               0.771186   
recall               0.777778              0.689655               0.805310   
f1-score             0.660377              0.695652               0.787879   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.779661         0.775862  0.824147    0.823021   
recall               0.867925         0.849057  0.824147    0.778691   
f1-score             0.821429         0.810811  0.824147    0.779200   
support             53.000000       106.000000  0.824147  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.834690  
recall         0.824147  
f1-score       0.823909  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s0,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk']]",0.8293963254593176,0.7643949078689783,0.7232026344266047,0.8361795623031179,0.8293963254593176,0.7296998185568636,0.823183504768488,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.250000          0.826087      0.964029     0.898396   
recall               0.111111          0.926829      0.985294     0.835821   
f1-score             0.153846          0.873563      0.974545     0.865979   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.794872              0.800000               0.801653   
recall               0.688889              0.413793               0.858407   
f1-score             0.738095              0.545455               0.829060   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.888889         0.655629  0.829396    0.764395   
recall               0.754717         0.933962  0.829396    0.723203   
f1-score             0.816327         0.770428  0.829396    0.729700   
support             53.000000       106.000000  0.829396  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.836180  
recall         0.829396  
f1-score       0.823184  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s0,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk']]",0.8280839895013123,0.8512683090293784,0.7376079894888189,0.8354627041989148,0.8280839895013123,0.7667269200736606,0.8229985034729496,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.795918      0.992593     0.808889   
recall               0.333333          0.951220      0.985294     0.905473   
f1-score             0.500000          0.866667      0.988930     0.854460   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.828571              0.736842               0.790909   
recall               0.644444              0.482759               0.769912   
f1-score             0.725000              0.583333               0.780269   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            1.000000         0.707692  0.828084    0.851268   
recall               0.698113         0.867925  0.828084    0.737608   
f1-score             0.822222         0.779661  0.828084    0.766727   
support             53.000000       106.000000  0.828084  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.835463  
recall         0.828084  
f1-score       0.822999  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s1,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc']]",0.7808398950131233,0.7114994509135828,0.7000770946576683,0.8034168197191683,0.7808398950131233,0.670429273661369,0.7703626977490654,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.115385          0.775510      0.984848     0.886364   
recall               0.333333          0.926829      0.955882     0.776119   
f1-score             0.171429          0.844444      0.970149     0.827586   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.846154              0.692308               0.706667   
recall               0.488889              0.155172               0.938053   
f1-score             0.619718              0.253521               0.806084   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.732394         0.663866   0.78084    0.711499   
recall               0.981132         0.745283   0.78084    0.700077   
f1-score             0.838710         0.702222   0.78084    0.670429   
support             53.000000       106.000000   0.78084  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.803417  
recall         0.780840  
f1-score       0.770363  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s1,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc']]",0.7467191601049868,0.703351539561251,0.6455072195887639,0.760601075858609,0.7467191601049868,0.6651543931312959,0.7457771169345094,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.333333          0.914286      1.000000     0.797030   
recall               0.222222          0.780488      0.970588     0.800995   
f1-score             0.266667          0.842105      0.985075     0.799007   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.812500              0.466667               0.542857   
recall               0.577778              0.362069               0.840708   
f1-score             0.675325              0.407767               0.659722   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.702128         0.761364  0.746719    0.703352   
recall               0.622642         0.632075  0.746719    0.645507   
f1-score             0.660000         0.690722  0.746719    0.665154   
support             53.000000       106.000000  0.746719  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.760601  
recall         0.746719  
f1-score       0.745777  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s1,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc']]",0.7624671916010499,0.6977806849579358,0.7208791864156251,0.7657069895909051,0.7624671916010499,0.7057885450279461,0.7606224906316985,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.363636          0.826087      0.984615     0.782609   
recall               0.444444          0.926829      0.941176     0.805970   
f1-score             0.400000          0.873563      0.962406     0.794118   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.750000               0.37931               0.756098   
recall               0.800000               0.37931               0.548673   
f1-score             0.774194               0.37931               0.635897   
support             45.000000              58.00000             113.000000   
Test                45.000000              58.00000             113.000000   
Train                5.000000               6.00000              12.000000   
Total               50.000000              64.00000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.725806         0.711864  0.762467    0.697781   
recall               0.849057         0.792453  0.762467    0.720879   
f1-score             0.782609         0.750000  0.762467    0.705789   
support             53.000000       106.000000  0.762467  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.765707  
recall         0.762467  
f1-score       0.760622  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s1,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc']]",0.7926509186351706,0.7497461560390621,0.7388452078183705,0.8178933048948724,0.7926509186351706,0.7219512658692542,0.7917241788106766,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.500000          0.512821      0.920290     0.942308   
recall               0.222222          0.975610      0.933824     0.731343   
f1-score             0.307692          0.672269      0.927007     0.823529   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.840909              0.750000               0.791304   
recall               0.822222              0.413793               0.805310   
f1-score             0.831461              0.533333               0.798246   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.859649         0.630435  0.792651    0.749746   
recall               0.924528         0.820755  0.792651    0.738845   
f1-score             0.890909         0.713115  0.792651    0.721951   
support             53.000000       106.000000  0.792651  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.817893  
recall         0.792651  
f1-score       0.791724  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s1,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc']]",0.7939632545931758,0.7349668372705361,0.7131313894930016,0.799221849144693,0.7939632545931758,0.7150639652146893,0.7920020608947365,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.333333          0.885714      0.871622     0.928571   
recall               0.111111          0.756098      0.948529     0.776119   
f1-score             0.166667          0.815789      0.908451     0.845528   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.826087              0.500000               0.714286   
recall               0.844444              0.465517               0.752212   
f1-score             0.835165              0.482143               0.732759   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.890909         0.664179  0.793963    0.734967   
recall               0.924528         0.839623  0.793963    0.713131   
f1-score             0.907407         0.741667  0.793963    0.715064   
support             53.000000       106.000000  0.793963  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.799222  
recall         0.793963  
f1-score       0.792002  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s1,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc']]",0.7887139107611548,0.7524510288159292,0.6990187539150495,0.7972751277796093,0.7887139107611548,0.7132432158689785,0.7860827280528462,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.333333          0.843750      0.938931     0.819512   
recall               0.111111          0.658537      0.904412     0.835821   
f1-score             0.166667          0.739726      0.921348     0.827586   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.883721              0.681818               0.768421   
recall               0.844444              0.517241               0.646018   
f1-score             0.863636              0.588235               0.701923   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.903846         0.598726  0.788714    0.752451   
recall               0.886792         0.886792  0.788714    0.699019   
f1-score             0.895238         0.714829  0.788714    0.713243   
support             53.000000       106.000000  0.788714  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.797275  
recall         0.788714  
f1-score       0.786083  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s2,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['com', 'tow', 'lc', 'sw', 'stem']]",0.7742782152230971,0.701281075246473,0.7517955003747243,0.8239574501806624,0.7742782152230971,0.6966051031048213,0.783374276223427,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.187500          0.727273      0.982609     0.913706   
recall               0.666667          0.780488      0.830882     0.895522   
f1-score             0.292683          0.752941      0.900398     0.904523   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.596154              0.716981               0.907692   
recall               0.688889              0.655172               0.522124   
f1-score             0.639175              0.684685               0.662921   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.520000         0.759615  0.774278    0.701281   
recall               0.981132         0.745283  0.774278    0.751796   
f1-score             0.679739         0.752381  0.774278    0.696605   
support             53.000000       106.000000  0.774278  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.823957  
recall         0.774278  
f1-score       0.783374  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s2,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['com', 'tow', 'lc', 'sw', 'stem']]",0.7322834645669292,0.6883409898762488,0.6457449866578852,0.7719274466980185,0.7322834645669292,0.6474582503078238,0.7421443747439038,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.500000          0.850000      1.000000     0.875000   
recall               0.333333          0.414634      0.955882     0.800995   
f1-score             0.400000          0.557377      0.977444     0.836364   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.278846              0.489796               0.750000   
recall               0.644444              0.413793               0.663717   
f1-score             0.389262              0.448598               0.704225   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.803279         0.648148  0.732283    0.688341   
recall               0.924528         0.660377  0.732283    0.645745   
f1-score             0.859649         0.654206  0.732283    0.647458   
support             53.000000       106.000000  0.732283  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.771927  
recall         0.732283  
f1-score       0.742144  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s2,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['com', 'tow', 'lc', 'sw', 'stem']]",0.7532808398950132,0.6817744979046148,0.7110072718108519,0.7763426914835758,0.7532808398950132,0.6702957730273345,0.755594158206532,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.193548          0.756757      0.978417     0.811828   
recall               0.666667          0.682927      1.000000     0.751244   
f1-score             0.300000          0.717949      0.989091     0.780362   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.471429              0.692308               0.729730   
recall               0.733333              0.310345               0.716814   
f1-score             0.573913              0.428571               0.723214   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.763636         0.738318  0.753281    0.681774   
recall               0.792453         0.745283  0.753281    0.711007   
f1-score             0.777778         0.741784  0.753281    0.670296   
support             53.000000       106.000000  0.753281  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.776343  
recall         0.753281  
f1-score       0.755594  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s2,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['com', 'tow', 'lc', 'sw', 'stem']]",0.8097112860892388,0.7155963729020929,0.7244726297097395,0.8132321471630531,0.8097112860892388,0.7176137635279232,0.8081601328527935,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.863636      0.984615     0.920000   
recall                    0.0          0.926829      0.941176     0.800995   
f1-score                  0.0          0.894118      0.962406     0.856383   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.863636              0.640000               0.678832   
recall               0.844444              0.551724               0.823009   
f1-score             0.853933              0.592593               0.744000   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.851852         0.637795  0.809711    0.715596   
recall               0.867925         0.764151  0.809711    0.724473   
f1-score             0.859813         0.695279  0.809711    0.717614   
support             53.000000       106.000000  0.809711  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.813232  
recall         0.809711  
f1-score       0.808160  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s2,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['com', 'tow', 'lc', 'sw', 'stem']]",0.8083989501312336,0.8253140872152286,0.7088226705805921,0.8263432964487916,0.8083989501312336,0.7315118297174947,0.8076581605305134,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.842105      0.978102     0.938202   
recall               0.222222          0.780488      0.985294     0.830846   
f1-score             0.363636          0.810127      0.981685     0.881266   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.964286              0.625000               0.664384   
recall               0.600000              0.517241               0.858407   
f1-score             0.739726              0.566038               0.749035   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.759259         0.656489  0.808399    0.825314   
recall               0.773585         0.811321  0.808399    0.708823   
f1-score             0.766355         0.725738  0.808399    0.731512   
support             53.000000       106.000000  0.808399  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.826343  
recall         0.808399  
f1-score       0.807658  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s2,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['com', 'tow', 'lc', 'sw', 'stem']]",0.8083989501312336,0.8292115229500022,0.6865450957375803,0.8282333188540282,0.8083989501312336,0.7259318627310544,0.8010522923898429,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.666667          0.965517      0.950704     0.758065   
recall               0.222222          0.682927      0.992647     0.935323   
f1-score             0.333333          0.800000      0.971223     0.837416   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.866667              0.694915               0.879518   
recall               0.577778              0.706897               0.646018   
f1-score             0.693333              0.700855               0.744898   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            1.000000         0.680851  0.808399    0.829212   
recall               0.509434         0.905660  0.808399    0.686545   
f1-score             0.675000         0.777328  0.808399    0.725932   
support             53.000000       106.000000  0.808399  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.828233  
recall         0.808399  
f1-score       0.801052  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s3,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw']]",0.7414698162729659,0.6418617080469198,0.6193587902689869,0.7495837376491532,0.7414698162729659,0.6233522742614365,0.7406171160025288,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          1.000000      0.975610     0.822917   
recall                    0.0          0.609756      0.882353     0.786070   
f1-score                  0.0          0.757576      0.926641     0.804071   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.638298              0.300000               0.724409   
recall               0.666667              0.258621               0.814159   
f1-score             0.652174              0.277778               0.766667   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.666667         0.648855   0.74147    0.641862   
recall               0.754717         0.801887   0.74147    0.619359   
f1-score             0.707965         0.717300   0.74147    0.623352   
support             53.000000       106.000000   0.74147  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.749584  
recall         0.741470  
f1-score       0.740617  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s3,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw']]",0.6929133858267716,0.6019908662287565,0.6052477229891903,0.7344113105014316,0.6929133858267716,0.596003429785119,0.7045462480254253,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.609756      0.977778     0.884354   
recall                    0.0          0.609756      0.970588     0.646766   
f1-score                  0.0          0.609756      0.974170     0.747126   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.432432              0.442308               0.557823   
recall               0.711111              0.396552               0.725664   
f1-score             0.537815              0.418182               0.630769   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.843137         0.670330  0.692913    0.601991   
recall               0.811321         0.575472  0.692913    0.605248   
f1-score             0.826923         0.619289  0.692913    0.596003   
support             53.000000       106.000000  0.692913  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.734411  
recall         0.692913  
f1-score       0.704546  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s3,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw']]",0.7296587926509186,0.6741950093738133,0.6904485333355479,0.7390434610283756,0.7296587926509186,0.6710863835514624,0.7224499885295278,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.266667          0.826087      0.920863     0.709016   
recall               0.444444          0.926829      0.941176     0.860697   
f1-score             0.333333          0.873563      0.930909     0.777528   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.625000              0.382353               0.741935   
recall               0.666667              0.448276               0.407080   
f1-score             0.645161              0.412698               0.525714   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.833333         0.762500  0.729659    0.674195   
recall               0.943396         0.575472  0.729659    0.690449   
f1-score             0.884956         0.655914  0.729659    0.671086   
support             53.000000       106.000000  0.729659  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.739043  
recall         0.729659  
f1-score       0.722450  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s3,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw']]",0.7532808398950132,0.7654734732385271,0.678668883471942,0.7794728206166789,0.7532808398950132,0.6725254947757346,0.7518559052699978,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.500000      0.814103     0.925000   
recall               0.111111          0.780488      0.933824     0.736318   
f1-score             0.200000          0.609524      0.869863     0.819945   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.878049              0.609756               0.795699   
recall               0.800000              0.431034               0.654867   
f1-score             0.837209              0.505051               0.718447   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.789474         0.577181  0.753281    0.765473   
recall               0.849057         0.811321  0.753281    0.678669   
f1-score             0.818182         0.674510  0.753281    0.672525   
support             53.000000       106.000000  0.753281  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.779473  
recall         0.753281  
f1-score       0.751856  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s3,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw']]",0.7519685039370079,0.7876397603860916,0.6549190427190195,0.7746121739337211,0.7519685039370079,0.6710457016324569,0.7511229295383627,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          1.000000      0.940741     0.908108   
recall               0.111111          0.853659      0.933824     0.835821   
f1-score             0.200000          0.921053      0.937269     0.870466   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            1.000000              0.435897               0.515723   
recall               0.622222              0.293103               0.725664   
f1-score             0.767123              0.350515               0.602941   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.666667         0.621622  0.751969    0.787640   
recall               0.867925         0.650943  0.751969    0.654919   
f1-score             0.754098         0.635945  0.751969    0.671046   
support             53.000000       106.000000  0.751969  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.774612  
recall         0.751969  
f1-score       0.751123  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s3,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw']]",0.7545931758530183,0.7717342172596704,0.673939130537385,0.7576425901981049,0.7545931758530183,0.67925784231086,0.7468994267802817,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.755556      0.933824     0.722467   
recall               0.111111          0.829268      0.933824     0.815920   
f1-score             0.200000          0.790698      0.933824     0.766355   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.780488              0.568627               0.743590   
recall               0.711111              0.500000               0.513274   
f1-score             0.744186              0.532110               0.607330   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.750000         0.691057  0.754593    0.771734   
recall               0.849057         0.801887  0.754593    0.673939   
f1-score             0.796460         0.742358  0.754593    0.679258   
support             53.000000       106.000000  0.754593  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.757643  
recall         0.754593  
f1-score       0.746899  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s4,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.8241469816272966,0.741161991368945,0.7293370982873353,0.8447529022387577,0.8241469816272966,0.7238445076467245,0.8248859771019548,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.863636      1.000000     0.906593   
recall                    0.0          0.926829      0.970588     0.820896   
f1-score                  0.0          0.894118      0.985075     0.861619   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.772727              0.906250               0.688742   
recall               0.755556              0.500000               0.920354   
f1-score             0.764045              0.644444               0.787879   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.708333         0.824176  0.824147    0.741162   
recall               0.962264         0.707547  0.824147    0.729337   
f1-score             0.816000         0.761421  0.824147    0.723845   
support             53.000000       106.000000  0.824147  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.844753  
recall         0.824147  
f1-score       0.824886  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s4,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.800524934383202,0.7286999615345953,0.6504426602017802,0.8077725338379008,0.800524934383202,0.6748263408085834,0.7944758719193333,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.857143      1.000000     0.828194   
recall                    0.0          0.439024      0.992647     0.935323   
f1-score                  0.0          0.580645      0.996310     0.878505   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.966667              0.690476               0.744828   
recall               0.644444              0.500000               0.955752   
f1-score             0.773333              0.580000               0.837209   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.862745         0.608247  0.800525    0.728700   
recall               0.830189         0.556604  0.800525    0.650443   
f1-score             0.846154         0.581281  0.800525    0.674826   
support             53.000000       106.000000  0.800525  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.807773  
recall         0.800525  
f1-score       0.794476  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s4,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.8031496062992126,0.7469826110525288,0.7633322792844106,0.8302644027272209,0.8031496062992126,0.7421447374032867,0.8080022912747169,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.333333          0.868421      0.950355     0.884146   
recall               0.444444          0.804878      0.985294     0.721393   
f1-score             0.380952          0.835443      0.967509     0.794521   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.439560              0.800000               0.789916   
recall               0.888889              0.551724               0.831858   
f1-score             0.588235              0.653061               0.810345   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.830189         0.826923   0.80315    0.746983   
recall               0.830189         0.811321   0.80315    0.763332   
f1-score             0.830189         0.819048   0.80315    0.742145   
support             53.000000       106.000000   0.80315  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.830264  
recall         0.803150  
f1-score       0.808002  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s4,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.8202099737532809,0.793293723491448,0.7759072441388768,0.8289228658282577,0.8202099737532809,0.7725751510118308,0.8200999198052029,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.750000           0.95122      0.943662     0.903030   
recall               0.333333           0.95122      0.985294     0.741294   
f1-score             0.461538           0.95122      0.964029     0.814208   
support              9.000000          41.00000    136.000000   201.000000   
Test                 9.000000          41.00000    136.000000   201.000000   
Train                1.000000           5.00000     15.000000    22.000000   
Total               10.000000          46.00000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.573770              0.701754               0.760684   
recall               0.777778              0.689655               0.787611   
f1-score             0.660377              0.695652               0.773913   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.779661         0.775862   0.82021    0.793294   
recall               0.867925         0.849057   0.82021    0.775907   
f1-score             0.821429         0.810811   0.82021    0.772575   
support             53.000000       106.000000   0.82021  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.828923  
recall         0.820210  
f1-score       0.820100  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s4,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.8267716535433071,0.8522098233809119,0.758406542986795,0.8571394442874399,0.8267716535433071,0.7651353844689679,0.8205574321414602,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          1.000000      1.000000     0.949045   
recall               0.333333          0.853659      0.970588     0.741294   
f1-score             0.500000          0.921053      0.985075     0.832402   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.581818              0.909091               0.692308   
recall               0.711111              0.344828               0.955752   
f1-score             0.640000              0.500000               0.802974   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.825397         0.712230  0.826772    0.852210   
recall               0.981132         0.933962  0.826772    0.758407   
f1-score             0.896552         0.808163  0.826772    0.765135   
support             53.000000       106.000000  0.826772  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.857139  
recall         0.826772  
f1-score       0.820557  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s4,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.8267716535433071,0.8307515184066319,0.776349715864465,0.8514993505699336,0.8267716535433071,0.7839088310687273,0.8271336079507593,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.800000          0.914286      0.971429     0.884146   
recall               0.444444          0.780488      1.000000     0.721393   
f1-score             0.571429          0.842105      0.985507     0.794521   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.513158              0.861111               0.833333   
recall               0.866667              0.534483               0.884956   
f1-score             0.644628              0.659574               0.858369   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            1.000000         0.699301  0.826772    0.830752   
recall               0.811321         0.943396  0.826772    0.776350   
f1-score             0.895833         0.803213  0.826772    0.783909   
support             53.000000       106.000000  0.826772  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.851499  
recall         0.826772  
f1-score       0.827134  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s5,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7427821522309711,0.6358651465248757,0.6378499302269627,0.7547518511527096,0.7427821522309711,0.6278766922887561,0.7404156258993506,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.780488      1.000000     0.840796   
recall                    0.0          0.780488      0.919118     0.840796   
f1-score                  0.0          0.780488      0.957854     0.840796   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.453125              0.615385               0.662069   
recall               0.644444              0.413793               0.849558   
f1-score             0.532110              0.494845               0.744186   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.718750         0.652174  0.742782    0.635865   
recall               0.867925         0.424528  0.742782    0.637850   
f1-score             0.786325         0.514286  0.742782    0.627877   
support             53.000000       106.000000  0.742782  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.754752  
recall         0.742782  
f1-score       0.740416  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s5,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.6929133858267716,0.695261887582854,0.578190823765488,0.722767178507601,0.6929133858267716,0.6092192031854746,0.693886403220554,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.750000          0.923077      1.000000     0.751196   
recall               0.333333          0.585366      0.919118     0.781095   
f1-score             0.461538          0.716418      0.957854     0.765854   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.136364              0.600000               0.560811   
recall               0.200000              0.206897               0.734513   
f1-score             0.162162              0.307692               0.636015   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.904762         0.631148  0.692913    0.695262   
recall               0.716981         0.726415  0.692913    0.578191   
f1-score             0.800000         0.675439  0.692913    0.609219   
support             53.000000       106.000000  0.692913  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.722767  
recall         0.692913  
f1-score       0.693886  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s5,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7296587926509186,0.6730804363402129,0.6900180407639909,0.738970160680507,0.7296587926509186,0.6699644691828078,0.721982962934209,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.266667          0.826087      0.927536     0.710204   
recall               0.444444          0.926829      0.941176     0.865672   
f1-score             0.333333          0.873563      0.934307     0.780269   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.625000              0.382353               0.737705   
recall               0.666667              0.448276               0.398230   
f1-score             0.645161              0.412698               0.517241   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.819672         0.762500  0.729659    0.673080   
recall               0.943396         0.575472  0.729659    0.690018   
f1-score             0.877193         0.655914  0.729659    0.669964   
support             53.000000       106.000000  0.729659  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.738970  
recall         0.729659  
f1-score       0.721983  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s5,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7519685039370079,0.7710125509374434,0.6704406367472449,0.7765239407901614,0.7519685039370079,0.6735474791573799,0.7541309433349649,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.969697      0.862745     0.882353   
recall               0.111111          0.780488      0.970588     0.746269   
f1-score             0.200000          0.864865      0.913495     0.808625   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.405063              0.600000               0.704762   
recall               0.711111              0.568966               0.654867   
f1-score             0.516129              0.584071               0.678899   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.847826         0.666667  0.751969    0.771013   
recall               0.735849         0.754717  0.751969    0.670441   
f1-score             0.787879         0.707965  0.751969    0.673547   
support             53.000000       106.000000  0.751969  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.776524  
recall         0.751969  
f1-score       0.754131  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s5,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7506561679790026,0.7921989736707462,0.6333318646204247,0.7794763362590866,0.7506561679790026,0.6617290747382223,0.7524608827054787,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.958333      0.957627     0.872549   
recall               0.111111          0.560976      0.830882     0.885572   
f1-score             0.200000          0.707692      0.889764     0.879012   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.777778              0.483871               0.606299   
recall               0.622222              0.517241               0.681416   
f1-score             0.691358              0.500000               0.641667   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.900000         0.573333  0.750656    0.792199   
recall               0.679245         0.811321  0.750656    0.633332   
f1-score             0.774194         0.671875  0.750656    0.661729   
support             53.000000       106.000000  0.750656  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.779476  
recall         0.750656  
f1-score       0.752461  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s5,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7559055118110236,0.7824222592533178,0.6568731575281519,0.7607017327365178,0.7559055118110236,0.6759122020725453,0.7496002748510977,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.967742      0.927007     0.748936   
recall               0.111111          0.731707      0.933824     0.875622   
f1-score             0.200000          0.833333      0.930403     0.807339   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.739130              0.400000               0.709302   
recall               0.755556              0.379310               0.539823   
f1-score             0.747253              0.389381               0.613065   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.877551         0.672131  0.755906    0.782422   
recall               0.811321         0.773585  0.755906    0.656873   
f1-score             0.843137         0.719298  0.755906    0.675912   
support             53.000000       106.000000  0.755906  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.760702  
recall         0.755906  
f1-score       0.749600  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s6,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7165354330708661,0.6185547898497427,0.6218142530635835,0.7202075054097629,0.7165354330708661,0.617743951268724,0.7160690763259537,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.812500      0.925620     0.767773   
recall                    0.0          0.951220      0.823529     0.805970   
f1-score                  0.0          0.876404      0.871595     0.786408   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.684211              0.322581               0.653543   
recall               0.577778              0.344828               0.734513   
f1-score             0.626506              0.333333               0.691667   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.689655         0.711111  0.716535    0.618555   
recall               0.754717         0.603774  0.716535    0.621814   
f1-score             0.720721         0.653061  0.716535    0.617744   
support             53.000000       106.000000  0.716535  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.720208  
recall         0.716535  
f1-score       0.716069  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s6,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.6614173228346457,0.5504492477659768,0.5273015362828499,0.6735503489726226,0.6614173228346457,0.5332818631109605,0.6607786038443099,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.564103      0.991736     0.637450   
recall                    0.0          0.536585      0.882353     0.796020   
f1-score                  0.0          0.550000      0.933852     0.707965   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.454545              0.245283               0.735849   
recall               0.333333              0.224138               0.690265   
f1-score             0.384615              0.234234               0.712329   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.588235         0.736842  0.661417    0.550449   
recall               0.754717         0.528302  0.661417    0.527302   
f1-score             0.661157         0.615385  0.661417    0.533282   
support             53.000000       106.000000  0.661417  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.673550  
recall         0.661417  
f1-score       0.660779  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s6,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7309711286089239,0.6832272701926462,0.6775006460482838,0.7632137884937311,0.7309711286089239,0.6660399736934135,0.737154673752914,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.120000          0.903226      0.974790     0.812500   
recall               0.333333          0.682927      0.852941     0.776119   
f1-score             0.176471          0.777778      0.909804     0.793893   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.703704              0.508475               0.714286   
recall               0.844444              0.517241               0.486726   
f1-score             0.767677              0.512821               0.578947   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.829787         0.582278  0.730971    0.683227   
recall               0.735849         0.867925  0.730971    0.677501   
f1-score             0.780000         0.696970  0.730971    0.666040   
support             53.000000       106.000000  0.730971  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.763214  
recall         0.730971  
f1-score       0.737155  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s6,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7454068241469817,0.6630515388087315,0.6682998179018652,0.7627576743511574,0.7454068241469817,0.6606451143166638,0.7473956351815119,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.111111          0.852941      0.827815     0.961039   
recall               0.111111          0.707317      0.919118     0.736318   
f1-score             0.111111          0.773333      0.871080     0.833803   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.701754              0.557692               0.663866   
recall               0.888889              0.500000               0.699115   
f1-score             0.784314              0.527273               0.681034   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.685185         0.606061  0.745407    0.663052   
recall               0.698113         0.754717  0.745407    0.668300   
f1-score             0.691589         0.672269  0.745407    0.660645   
support             53.000000       106.000000  0.745407  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.762758  
recall         0.745407  
f1-score       0.747396  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s6,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7480314960629921,0.6769946971926312,0.6416980705912245,0.7598779715452453,0.7480314960629921,0.6487275898239823,0.7441592435850104,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          1.000000      0.783951     0.883721   
recall                    0.0          0.707317      0.933824     0.756219   
f1-score                  0.0          0.828571      0.852349     0.815013   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.634615              0.500000               0.716981   
recall               0.733333              0.396552               0.672566   
f1-score             0.680412              0.442308               0.694064   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.973684         0.600000  0.748031    0.676995   
recall               0.698113         0.877358  0.748031    0.641698   
f1-score             0.813187         0.712644  0.748031    0.648728   
support             53.000000       106.000000  0.748031  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.759878  
recall         0.748031  
f1-score       0.744159  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s6,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7585301837270341,0.6776145262229165,0.6635750746209171,0.7604181845938943,0.7585301837270341,0.6636393004115538,0.7520153312239621,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.897436      0.931298     0.774336   
recall                    0.0          0.853659      0.897059     0.870647   
f1-score                  0.0          0.875000      0.913858     0.819672   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.750000              0.486486               0.733333   
recall               0.800000              0.620690               0.486726   
f1-score             0.774194              0.545455               0.585106   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.871795         0.653846   0.75853    0.677615   
recall               0.641509         0.801887   0.75853    0.663575   
f1-score             0.739130         0.720339   0.75853    0.663639   
support             53.000000       106.000000   0.75853  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.760418  
recall         0.758530  
f1-score       0.752015  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s7,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['com', 'tow', 'lc', 'sw', 'stem'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.699475065616798,0.6419915515085427,0.6081995446765421,0.7153010501236703,0.699475065616798,0.6002883124910662,0.6980423940224054,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.500000          0.634146      1.000000     0.781095   
recall               0.111111          0.634146      0.882353     0.781095   
f1-score             0.181818          0.634146      0.937500     0.781095   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.634615              0.531250               0.642857   
recall               0.733333              0.293103               0.557522   
f1-score             0.680412              0.377778               0.597156   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.418367         0.635593  0.699475    0.641992   
recall               0.773585         0.707547  0.699475    0.608200   
f1-score             0.543046         0.669643  0.699475    0.600288   
support             53.000000       106.000000  0.699475  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.715301  
recall         0.699475  
f1-score       0.698042  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s7,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['com', 'tow', 'lc', 'sw', 'stem'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.6443569553805775,0.5960902405794879,0.5567925104995263,0.6827523690855541,0.6443569553805775,0.55260662573694,0.6390200264974601,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.727273      1.000000     0.600733   
recall                    0.0          0.780488      0.794118     0.815920   
f1-score                  0.0          0.752941      0.885246     0.691983   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.729730              0.612903               0.732143   
recall               0.600000              0.327586               0.362832   
f1-score             0.658537              0.426966               0.485207   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.366071         0.595960  0.644357    0.596090   
recall               0.773585         0.556604  0.644357    0.556793   
f1-score             0.496970         0.575610  0.644357    0.552607   
support             53.000000       106.000000  0.644357  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.682752  
recall         0.644357  
f1-score       0.639020  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s7,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['com', 'tow', 'lc', 'sw', 'stem'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7545931758530183,0.6682691891101054,0.7001423369197122,0.7693084678014,0.7545931758530183,0.6783492622097991,0.7587885282532492,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.111111          0.780488      0.956522     0.852273   
recall               0.222222          0.780488      0.970588     0.746269   
f1-score             0.148148          0.780488      0.963504     0.795756   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.621212              0.437500               0.653465   
recall               0.911111              0.482759               0.584071   
f1-score             0.738739              0.459016               0.616822   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.851852         0.750000  0.754593    0.668269   
recall               0.867925         0.735849  0.754593    0.700142   
f1-score             0.859813         0.742857  0.754593    0.678349   
support             53.000000       106.000000  0.754593  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.769308  
recall         0.754593  
f1-score       0.758789  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s7,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['com', 'tow', 'lc', 'sw', 'stem'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7690288713910761,0.7729939637467056,0.6935478230759542,0.7867948099582919,0.7690288713910761,0.688676587842399,0.7696199713448311,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.777778      0.984127     0.892655   
recall               0.111111          0.853659      0.911765     0.786070   
f1-score             0.200000          0.813953      0.946565     0.835979   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.864865              0.474576               0.691667   
recall               0.711111              0.482759               0.734513   
f1-score             0.780488              0.478632               0.712446   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.641026         0.630252  0.769029    0.772994   
recall               0.943396         0.707547  0.769029    0.693548   
f1-score             0.763359         0.666667  0.769029    0.688677   
support             53.000000       106.000000  0.769029  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.786795  
recall         0.769029  
f1-score       0.769620  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s7,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['com', 'tow', 'lc', 'sw', 'stem'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7624671916010499,0.798444170666393,0.6519683845330142,0.7847871139865891,0.7624671916010499,0.6694593343211817,0.7571971893877948,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          1.000000      1.000000     0.830769   
recall               0.111111          0.658537      0.911765     0.805970   
f1-score             0.200000          0.794118      0.953846     0.818182   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.729730              0.703704               0.621795   
recall               0.600000              0.327586               0.858407   
f1-score             0.658537              0.447059               0.721190   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.692308         0.607692  0.762467    0.798444   
recall               0.849057         0.745283  0.762467    0.651968   
f1-score             0.762712         0.669492  0.762467    0.669459   
support             53.000000       106.000000  0.762467  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.784787  
recall         0.762467  
f1-score       0.757197  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s7,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['com', 'tow', 'lc', 'sw', 'stem'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7821522309711286,0.8087949545002782,0.6978141881488606,0.7892246377019829,0.7821522309711286,0.7112159875531382,0.7781090731064789,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.900000      0.975610     0.733906   
recall               0.111111          0.878049      0.882353     0.850746   
f1-score             0.200000          0.888889      0.926641     0.788018   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.775000              0.620000               0.768421   
recall               0.688889              0.534483               0.646018   
f1-score             0.729412              0.574074               0.701923   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.793103         0.713115  0.782152    0.808795   
recall               0.867925         0.820755  0.782152    0.697814   
f1-score             0.828829         0.763158  0.782152    0.711216   
support             53.000000       106.000000  0.782152  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.789225  
recall         0.782152  
f1-score       0.778109  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
