classifier,setting_id,Feature rep.,settings,accuracy,macro_precision,macro_recall,weighted_precision,weighted_recall,macro_f1,weighted_f1,train_size,test_size,report_table
MaxEnt,s0,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'stem'], ['pac', 'tow', 'jk']]",0.8254593175853019,0.7228863389570708,0.7103263865199343,0.8217183298662325,0.8254593175853019,0.7065587603229884,0.8161597083596642,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.888889      0.985507     0.931034   
recall                    0.0          0.975610      1.000000     0.940299   
f1-score                  0.0          0.930233      0.992701     0.935644   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            1.000000              0.571429               0.664384   
recall               0.688889              0.344828               0.858407   
f1-score             0.815789              0.430108               0.749035   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.753623         0.711111  0.825459    0.722886   
recall               0.981132         0.603774  0.825459    0.710326   
f1-score             0.852459         0.653061  0.825459    0.706559   
support             53.000000       106.000000  0.825459  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.821718  
recall         0.825459  
f1-score       0.816160  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s0,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'stem'], ['pac', 'tow', 'jk']]",0.8018372703412073,0.7355251390782995,0.6932117477721498,0.8077045558082254,0.8018372703412073,0.7009575063255183,0.7953132673812828,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.166667          0.900000      1.000000     0.877451   
recall               0.222222          0.878049      0.985294     0.890547   
f1-score             0.190476          0.888889      0.992593     0.883951   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.956522              0.487179               0.675000   
recall               0.488889              0.327586               0.955752   
f1-score             0.647059              0.391753               0.791209   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.903846         0.653061  0.801837    0.735525   
recall               0.886792         0.603774  0.801837    0.693212   
f1-score             0.895238         0.627451  0.801837    0.700958   
support             53.000000       106.000000  0.801837  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.807705  
recall         0.801837  
f1-score       0.795313  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s0,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'stem'], ['pac', 'tow', 'jk']]",0.8044619422572179,0.7383164608887153,0.7469766331353123,0.8238125377143857,0.8044619422572179,0.7343527602216086,0.8081293248478201,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.300000          0.875000      0.992424     0.878613   
recall               0.333333          0.853659      0.963235     0.756219   
f1-score             0.315789          0.864198      0.977612     0.812834   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.493333              0.850000               0.794872   
recall               0.822222              0.586207               0.823009   
f1-score             0.616667              0.693878               0.808696   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.727273         0.733333  0.804462    0.738316   
recall               0.754717         0.830189  0.804462    0.746977   
f1-score             0.740741         0.778761  0.804462    0.734353   
support             53.000000       106.000000  0.804462  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.823813  
recall         0.804462  
f1-score       0.808129  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s0,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'stem'], ['pac', 'tow', 'jk']]",0.8241469816272966,0.8230209383264849,0.7786908059411789,0.8346899909177832,0.8241469816272966,0.7791997651747621,0.8239092376918177,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000           0.95122      0.950704     0.903030   
recall               0.333333           0.95122      0.992647     0.741294   
f1-score             0.500000           0.95122      0.971223     0.814208   
support              9.000000          41.00000    136.000000   201.000000   
Test                 9.000000          41.00000    136.000000   201.000000   
Train                1.000000           5.00000     15.000000    22.000000   
Total               10.000000          46.00000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.573770              0.701754               0.771186   
recall               0.777778              0.689655               0.805310   
f1-score             0.660377              0.695652               0.787879   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.779661         0.775862  0.824147    0.823021   
recall               0.867925         0.849057  0.824147    0.778691   
f1-score             0.821429         0.810811  0.824147    0.779200   
support             53.000000       106.000000  0.824147  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.834690  
recall         0.824147  
f1-score       0.823909  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s0,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'stem'], ['pac', 'tow', 'jk']]",0.8307086614173228,0.7651999682538314,0.7252990704853048,0.8376216440793565,0.8307086614173228,0.7312769263891802,0.8246053630538087,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.250000          0.826087      0.964029     0.903226   
recall               0.111111          0.926829      0.985294     0.835821   
f1-score             0.153846          0.873563      0.974545     0.868217   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.794872              0.800000               0.801653   
recall               0.688889              0.413793               0.858407   
f1-score             0.738095              0.545455               0.829060   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.891304         0.655629  0.830709    0.765200   
recall               0.773585         0.933962  0.830709    0.725299   
f1-score             0.828283         0.770428  0.830709    0.731277   
support             53.000000       106.000000  0.830709  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.837622  
recall         0.830709  
f1-score       0.824605  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s0,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'stem'], ['pac', 'tow', 'jk']]",0.8280839895013123,0.8328508007163938,0.7499295036533883,0.8342271793479203,0.8280839895013123,0.7599963144202623,0.8255519857621815,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          1.000000      0.985294     0.858537   
recall               0.222222          0.829268      0.985294     0.875622   
f1-score             0.363636          0.906667      0.985294     0.866995   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.804348              0.566038               0.858586   
recall               0.822222              0.517241               0.752212   
f1-score             0.813187              0.540541               0.801887   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.712329         0.710526  0.828084    0.832851   
recall               0.981132         0.764151  0.828084    0.749930   
f1-score             0.825397         0.736364  0.828084    0.759996   
support             53.000000       106.000000  0.828084  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.834227  
recall         0.828084  
f1-score       0.825552  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s1,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc']]",0.7808398950131233,0.7114994509135828,0.7000770946576683,0.8034168197191683,0.7808398950131233,0.670429273661369,0.7703626977490654,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.115385          0.775510      0.984848     0.886364   
recall               0.333333          0.926829      0.955882     0.776119   
f1-score             0.171429          0.844444      0.970149     0.827586   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.846154              0.692308               0.706667   
recall               0.488889              0.155172               0.938053   
f1-score             0.619718              0.253521               0.806084   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.732394         0.663866   0.78084    0.711499   
recall               0.981132         0.745283   0.78084    0.700077   
f1-score             0.838710         0.702222   0.78084    0.670429   
support             53.000000       106.000000   0.78084  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.803417  
recall         0.780840  
f1-score       0.770363  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s1,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc']]",0.7467191601049868,0.703351539561251,0.6455072195887639,0.760601075858609,0.7467191601049868,0.6651543931312959,0.7457771169345094,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.333333          0.914286      1.000000     0.797030   
recall               0.222222          0.780488      0.970588     0.800995   
f1-score             0.266667          0.842105      0.985075     0.799007   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.812500              0.466667               0.542857   
recall               0.577778              0.362069               0.840708   
f1-score             0.675325              0.407767               0.659722   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.702128         0.761364  0.746719    0.703352   
recall               0.622642         0.632075  0.746719    0.645507   
f1-score             0.660000         0.690722  0.746719    0.665154   
support             53.000000       106.000000  0.746719  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.760601  
recall         0.746719  
f1-score       0.745777  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s1,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc']]",0.7624671916010499,0.6977806849579358,0.7208791864156251,0.7657069895909051,0.7624671916010499,0.7057885450279461,0.7606224906316985,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.363636          0.826087      0.984615     0.782609   
recall               0.444444          0.926829      0.941176     0.805970   
f1-score             0.400000          0.873563      0.962406     0.794118   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.750000               0.37931               0.756098   
recall               0.800000               0.37931               0.548673   
f1-score             0.774194               0.37931               0.635897   
support             45.000000              58.00000             113.000000   
Test                45.000000              58.00000             113.000000   
Train                5.000000               6.00000              12.000000   
Total               50.000000              64.00000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.725806         0.711864  0.762467    0.697781   
recall               0.849057         0.792453  0.762467    0.720879   
f1-score             0.782609         0.750000  0.762467    0.705789   
support             53.000000       106.000000  0.762467  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.765707  
recall         0.762467  
f1-score       0.760622  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s1,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc']]",0.7926509186351706,0.7497461560390621,0.7388452078183705,0.8178933048948724,0.7926509186351706,0.7219512658692542,0.7917241788106766,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.500000          0.512821      0.920290     0.942308   
recall               0.222222          0.975610      0.933824     0.731343   
f1-score             0.307692          0.672269      0.927007     0.823529   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.840909              0.750000               0.791304   
recall               0.822222              0.413793               0.805310   
f1-score             0.831461              0.533333               0.798246   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.859649         0.630435  0.792651    0.749746   
recall               0.924528         0.820755  0.792651    0.738845   
f1-score             0.890909         0.713115  0.792651    0.721951   
support             53.000000       106.000000  0.792651  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.817893  
recall         0.792651  
f1-score       0.791724  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s1,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc']]",0.7939632545931758,0.7349668372705361,0.7131313894930016,0.799221849144693,0.7939632545931758,0.7150639652146893,0.7920020608947365,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.333333          0.885714      0.871622     0.928571   
recall               0.111111          0.756098      0.948529     0.776119   
f1-score             0.166667          0.815789      0.908451     0.845528   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.826087              0.500000               0.714286   
recall               0.844444              0.465517               0.752212   
f1-score             0.835165              0.482143               0.732759   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.890909         0.664179  0.793963    0.734967   
recall               0.924528         0.839623  0.793963    0.713131   
f1-score             0.907407         0.741667  0.793963    0.715064   
support             53.000000       106.000000  0.793963  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.799222  
recall         0.793963  
f1-score       0.792002  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s1,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc']]",0.7887139107611548,0.7524510288159292,0.6990187539150495,0.7972751277796093,0.7887139107611548,0.7132432158689785,0.7860827280528462,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.333333          0.843750      0.938931     0.819512   
recall               0.111111          0.658537      0.904412     0.835821   
f1-score             0.166667          0.739726      0.921348     0.827586   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.883721              0.681818               0.768421   
recall               0.844444              0.517241               0.646018   
f1-score             0.863636              0.588235               0.701923   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.903846         0.598726  0.788714    0.752451   
recall               0.886792         0.886792  0.788714    0.699019   
f1-score             0.895238         0.714829  0.788714    0.713243   
support             53.000000       106.000000  0.788714  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.797275  
recall         0.788714  
f1-score       0.786083  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s2,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['com', 'tow', 'lc', 'sw', 'stem']]",0.7742782152230971,0.701281075246473,0.7517955003747243,0.8239574501806624,0.7742782152230971,0.6966051031048213,0.783374276223427,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.187500          0.727273      0.982609     0.913706   
recall               0.666667          0.780488      0.830882     0.895522   
f1-score             0.292683          0.752941      0.900398     0.904523   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.596154              0.716981               0.907692   
recall               0.688889              0.655172               0.522124   
f1-score             0.639175              0.684685               0.662921   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.520000         0.759615  0.774278    0.701281   
recall               0.981132         0.745283  0.774278    0.751796   
f1-score             0.679739         0.752381  0.774278    0.696605   
support             53.000000       106.000000  0.774278  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.823957  
recall         0.774278  
f1-score       0.783374  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s2,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['com', 'tow', 'lc', 'sw', 'stem']]",0.7322834645669292,0.6883409898762488,0.6457449866578852,0.7719274466980185,0.7322834645669292,0.6474582503078238,0.7421443747439038,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.500000          0.850000      1.000000     0.875000   
recall               0.333333          0.414634      0.955882     0.800995   
f1-score             0.400000          0.557377      0.977444     0.836364   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.278846              0.489796               0.750000   
recall               0.644444              0.413793               0.663717   
f1-score             0.389262              0.448598               0.704225   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.803279         0.648148  0.732283    0.688341   
recall               0.924528         0.660377  0.732283    0.645745   
f1-score             0.859649         0.654206  0.732283    0.647458   
support             53.000000       106.000000  0.732283  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.771927  
recall         0.732283  
f1-score       0.742144  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s2,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['com', 'tow', 'lc', 'sw', 'stem']]",0.7532808398950132,0.6874999465404197,0.6740085145530972,0.7850075610976227,0.7532808398950132,0.6652588601400311,0.7611872893344327,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.050000          0.782609      0.992126     0.764706   
recall               0.222222          0.878049      0.926471     0.840796   
f1-score             0.081633          0.827586      0.958175     0.800948   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.716981              0.714286               0.801980   
recall               0.844444              0.344828               0.716814   
f1-score             0.775510              0.465116               0.757009   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.603448         0.761364  0.753281    0.687500   
recall               0.660377         0.632075  0.753281    0.674009   
f1-score             0.630631         0.690722  0.753281    0.665259   
support             53.000000       106.000000  0.753281  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.785008  
recall         0.753281  
f1-score       0.761187  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s2,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['com', 'tow', 'lc', 'sw', 'stem']]",0.8097112860892388,0.7155963729020929,0.7244726297097395,0.8132321471630531,0.8097112860892388,0.7176137635279232,0.8081601328527935,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.863636      0.984615     0.920000   
recall                    0.0          0.926829      0.941176     0.800995   
f1-score                  0.0          0.894118      0.962406     0.856383   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.863636              0.640000               0.678832   
recall               0.844444              0.551724               0.823009   
f1-score             0.853933              0.592593               0.744000   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.851852         0.637795  0.809711    0.715596   
recall               0.867925         0.764151  0.809711    0.724473   
f1-score             0.859813         0.695279  0.809711    0.717614   
support             53.000000       106.000000  0.809711  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.813232  
recall         0.809711  
f1-score       0.808160  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s2,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['com', 'tow', 'lc', 'sw', 'stem']]",0.8083989501312336,0.8253140872152286,0.7088226705805921,0.8263432964487916,0.8083989501312336,0.7315118297174947,0.8076581605305134,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.842105      0.978102     0.938202   
recall               0.222222          0.780488      0.985294     0.830846   
f1-score             0.363636          0.810127      0.981685     0.881266   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.964286              0.625000               0.664384   
recall               0.600000              0.517241               0.858407   
f1-score             0.739726              0.566038               0.749035   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.759259         0.656489  0.808399    0.825314   
recall               0.773585         0.811321  0.808399    0.708823   
f1-score             0.766355         0.725738  0.808399    0.731512   
support             53.000000       106.000000  0.808399  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.826343  
recall         0.808399  
f1-score       0.807658  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s2,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['com', 'tow', 'lc', 'sw', 'stem']]",0.8083989501312336,0.8292115229500022,0.6865450957375803,0.8282333188540282,0.8083989501312336,0.7259318627310544,0.8010522923898429,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.666667          0.965517      0.950704     0.758065   
recall               0.222222          0.682927      0.992647     0.935323   
f1-score             0.333333          0.800000      0.971223     0.837416   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.866667              0.694915               0.879518   
recall               0.577778              0.706897               0.646018   
f1-score             0.693333              0.700855               0.744898   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            1.000000         0.680851  0.808399    0.829212   
recall               0.509434         0.905660  0.808399    0.686545   
f1-score             0.675000         0.777328  0.808399    0.725932   
support             53.000000       106.000000  0.808399  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.828233  
recall         0.808399  
f1-score       0.801052  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s3,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'scw', 'jk', 'lc', 'sw']]",0.7427821522309711,0.6846955505900795,0.6612048396785748,0.7628555060611394,0.7427821522309711,0.6667254435463421,0.747174064196348,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.285714          0.965517      1.000000     0.828402   
recall               0.222222          0.682927      0.933824     0.696517   
f1-score             0.250000          0.800000      0.965779     0.756757   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.509804              0.430769               0.701613   
recall               0.577778              0.482759               0.769912   
f1-score             0.541667              0.455285               0.734177   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.816327         0.624113  0.742782    0.684696   
recall               0.754717         0.830189  0.742782    0.661205   
f1-score             0.784314         0.712551  0.742782    0.666725   
support             53.000000       106.000000  0.742782  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.762856  
recall         0.742782  
f1-score       0.747174  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s3,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'scw', 'jk', 'lc', 'sw']]",0.6929133858267716,0.6420525124689576,0.6038477582423039,0.697464222389155,0.6929133858267716,0.6044091521844712,0.6835334097396305,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.294118          0.761905      0.983871     0.699620   
recall               0.555556          0.390244      0.897059     0.915423   
f1-score             0.384615          0.516129      0.938462     0.793103   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.620000              0.548387               0.612069   
recall               0.688889              0.293103               0.628319   
f1-score             0.652632              0.382022               0.620087   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.738095         0.520408  0.692913    0.642053   
recall               0.584906         0.481132  0.692913    0.603848   
f1-score             0.652632         0.500000  0.692913    0.604409   
support             53.000000       106.000000  0.692913  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.697464  
recall         0.692913  
f1-score       0.683533  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s3,Bag-of-words,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'scw', 'jk', 'lc', 'sw']]",0.7309711286089239,0.6917411699406829,0.6621304363662363,0.7714442542327029,0.7309711286089239,0.6564735717401402,0.7382687329667479,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.085714          1.000000      0.975610     0.802956   
recall               0.333333          0.634146      0.882353     0.810945   
f1-score             0.136364          0.776119      0.926641     0.806931   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.714286              0.482143               0.750000   
recall               0.777778              0.465517               0.451327   
f1-score             0.744681              0.473684               0.563536   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.808511         0.606452  0.730971    0.691741   
recall               0.716981         0.886792  0.730971    0.662130   
f1-score             0.760000         0.720307  0.730971    0.656474   
support             53.000000       106.000000  0.730971  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.771444  
recall         0.730971  
f1-score       0.738269  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s3,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'scw', 'jk', 'lc', 'sw']]",0.7545931758530183,0.7780540183286899,0.6588579728217798,0.7647898981094748,0.7545931758530183,0.6726637679759885,0.7511051301942306,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.972222      0.905797     0.853403   
recall               0.111111          0.853659      0.919118     0.810945   
f1-score             0.200000          0.909091      0.912409     0.831633   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.793103              0.521739               0.653543   
recall               0.511111              0.413793               0.734513   
f1-score             0.621622              0.461538               0.691667   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.730159         0.572519  0.754593    0.778054   
recall               0.867925         0.707547  0.754593    0.658858   
f1-score             0.793103         0.632911  0.754593    0.672664   
support             53.000000       106.000000  0.754593  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.764790  
recall         0.754593  
f1-score       0.751105  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s3,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'scw', 'jk', 'lc', 'sw']]",0.7532808398950132,0.6943779391648618,0.6590013955593849,0.7976512844419763,0.7532808398950132,0.6619366876756234,0.7614182286089157,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          1.000000      0.991071     0.939394   
recall                    0.0          0.634146      0.816176     0.771144   
f1-score                  0.0          0.776119      0.895161     0.846995   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.942857              0.412500               0.735849   
recall               0.733333              0.568966               0.690265   
f1-score             0.825000              0.478261               0.712329   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.687500         0.540230  0.753281    0.694378   
recall               0.830189         0.886792  0.753281    0.659001   
f1-score             0.752137         0.671429  0.753281    0.661937   
support             53.000000       106.000000  0.753281  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.797651  
recall         0.753281  
f1-score       0.761418  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s3,TF-IDF,"[['lib', 'tow', 'scw', 'jk', 'lc', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'scw', 'jk', 'lc', 'sw']]",0.7572178477690289,0.7748596685503535,0.6754752063040776,0.7621019367365507,0.7572178477690289,0.6812594114529368,0.7499801365914233,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.755556      0.940741     0.730088   
recall               0.111111          0.829268      0.933824     0.820896   
f1-score             0.200000          0.790698      0.937269     0.772834   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.780488              0.568627               0.766234   
recall               0.711111              0.500000               0.522124   
f1-score             0.744186              0.532110               0.621053   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.762712         0.669291  0.757218    0.774860   
recall               0.849057         0.801887  0.757218    0.675475   
f1-score             0.803571         0.729614  0.757218    0.681259   
support             53.000000       106.000000  0.757218  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.762102  
recall         0.757218  
f1-score       0.749980  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s4,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.8241469816272966,0.7398293418950803,0.7358078923715654,0.8398137180898105,0.8241469816272966,0.7266247129672975,0.8266956979925618,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.142857          0.888889      1.000000     0.890625   
recall               0.333333          0.780488      0.985294     0.850746   
f1-score             0.200000          0.831169      0.992593     0.870229   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.783784              0.710526               0.798450   
recall               0.644444              0.465517               0.911504   
f1-score             0.707317              0.562500               0.851240   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.613333         0.830000  0.824147    0.739829   
recall               0.867925         0.783019  0.824147    0.735808   
f1-score             0.718750         0.805825  0.824147    0.726625   
support             53.000000       106.000000  0.824147  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.839814  
recall         0.824147  
f1-score       0.826696  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s4,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.800524934383202,0.7143123240690522,0.7099976593537568,0.795541747244504,0.800524934383202,0.7070987389865917,0.794262890619868,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.111111          0.930233      1.000000     0.842105   
recall               0.111111          0.975610      0.985294     0.875622   
f1-score             0.111111          0.952381      0.992593     0.858537   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.815789              0.567568               0.679389   
recall               0.688889              0.362069               0.787611   
f1-score             0.746988              0.442105               0.729508   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.787879         0.694737  0.800525    0.714312   
recall               0.981132         0.622642  0.800525    0.709998   
f1-score             0.873950         0.656716  0.800525    0.707099   
support             53.000000       106.000000  0.800525  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.795542  
recall         0.800525  
f1-score       0.794263  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s4,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.8018372703412073,0.7279499358960405,0.7489335235242434,0.8076858076864513,0.8018372703412073,0.7345902885228939,0.8019010664714202,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.333333          0.822222      0.957143     0.827225   
recall               0.333333          0.902439      0.985294     0.786070   
f1-score             0.333333          0.860465      0.971014     0.806122   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.545455              0.678571               0.793478   
recall               0.800000              0.655172               0.646018   
f1-score             0.648649              0.666667               0.712195   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.759259         0.834862  0.801837    0.727950   
recall               0.773585         0.858491  0.801837    0.748934   
f1-score             0.766355         0.846512  0.801837    0.734590   
support             53.000000       106.000000  0.801837  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.807686  
recall         0.801837  
f1-score       0.801901  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s4,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.8202099737532809,0.793293723491448,0.7759072441388768,0.8289228658282577,0.8202099737532809,0.7725751510118308,0.8200999198052029,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.750000           0.95122      0.943662     0.903030   
recall               0.333333           0.95122      0.985294     0.741294   
f1-score             0.461538           0.95122      0.964029     0.814208   
support              9.000000          41.00000    136.000000   201.000000   
Test                 9.000000          41.00000    136.000000   201.000000   
Train                1.000000           5.00000     15.000000    22.000000   
Total               10.000000          46.00000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.573770              0.701754               0.760684   
recall               0.777778              0.689655               0.787611   
f1-score             0.660377              0.695652               0.773913   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.779661         0.775862   0.82021    0.793294   
recall               0.867925         0.849057   0.82021    0.775907   
f1-score             0.821429         0.810811   0.82021    0.772575   
support             53.000000       106.000000   0.82021  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.828923  
recall         0.820210  
f1-score       0.820100  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s4,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.8267716535433071,0.8528615755542114,0.7390031071928005,0.8543269863756069,0.8267716535433071,0.7561462184583091,0.8266330791713004,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          1.000000      0.937500     0.938650   
recall               0.222222          0.756098      0.992647     0.761194   
f1-score             0.363636          0.861111      0.964286     0.840659   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.453125              0.885714               0.746479   
recall               0.644444              0.534483               0.938053   
f1-score             0.532110              0.666667               0.831373   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            1.000000         0.714286  0.826772    0.852862   
recall               0.905660         0.896226  0.826772    0.739003   
f1-score             0.950495         0.794979  0.826772    0.756146   
support             53.000000       106.000000  0.826772  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.854327  
recall         0.826772  
f1-score       0.826633  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s4,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.8267716535433071,0.8422532760476406,0.7717668408763969,0.8338100667248491,0.8267716535433071,0.7749990112284455,0.8239564600704551,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.975000      0.985294     0.801932   
recall               0.222222          0.951220      0.985294     0.825871   
f1-score             0.363636          0.962963      0.985294     0.813725   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.621212              0.673077               0.833333   
recall               0.911111              0.603448               0.663717   
f1-score             0.738739              0.636364               0.738916   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.927273         0.763158  0.826772    0.842253   
recall               0.962264         0.820755  0.826772    0.771767   
f1-score             0.944444         0.790909  0.826772    0.774999   
support             53.000000       106.000000  0.826772  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.833810  
recall         0.826772  
f1-score       0.823956  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s5,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7414698162729659,0.6775494438285874,0.6549366281601305,0.758063572989719,0.7414698162729659,0.6609008185246963,0.7448694852823878,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.250000          0.965517      1.000000     0.813953   
recall               0.222222          0.682927      0.948529     0.696517   
f1-score             0.235294          0.800000      0.973585     0.750670   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.500000              0.421875               0.679688   
recall               0.533333              0.465517               0.769912   
f1-score             0.516129              0.442623               0.721992   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.812500         0.654412   0.74147    0.677549   
recall               0.735849         0.839623   0.74147    0.654937   
f1-score             0.772277         0.735537   0.74147    0.660901   
support             53.000000       106.000000   0.74147  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.758064  
recall         0.741470  
f1-score       0.744869  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s5,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.6929133858267716,0.6047348372074453,0.5722231761922372,0.7134158020512035,0.6929133858267716,0.5783916568891025,0.6959685603824971,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.870968      0.960938     0.785340   
recall                    0.0          0.658537      0.904412     0.746269   
f1-score                  0.0          0.750000      0.931818     0.765306   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.406250              0.709677               0.601399   
recall               0.577778              0.379310               0.761062   
f1-score             0.477064              0.494382               0.671875   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.480769         0.627273  0.692913    0.604735   
recall               0.471698         0.650943  0.692913    0.572223   
f1-score             0.476190         0.638889  0.692913    0.578392   
support             53.000000       106.000000  0.692913  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.713416  
recall         0.692913  
f1-score       0.695969  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s5,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7283464566929134,0.6839186094615756,0.6655852930162761,0.7622469207047902,0.7283464566929134,0.6574604839388944,0.7335059398701008,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.107143          0.964286      0.975410     0.789216   
recall               0.333333          0.658537      0.875000     0.800995   
f1-score             0.162162          0.782609      0.922481     0.795062   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.686275              0.483871               0.735294   
recall               0.777778              0.517241               0.442478   
f1-score             0.729167              0.500000               0.552486   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.808511         0.605263  0.728346    0.683919   
recall               0.716981         0.867925  0.728346    0.665585   
f1-score             0.760000         0.713178  0.728346    0.657460   
support             53.000000       106.000000  0.728346  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.762247  
recall         0.728346  
f1-score       0.733506  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s5,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7519685039370079,0.7710125509374434,0.6704406367472449,0.7765239407901614,0.7519685039370079,0.6735474791573799,0.7541309433349649,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.969697      0.862745     0.882353   
recall               0.111111          0.780488      0.970588     0.746269   
f1-score             0.200000          0.864865      0.913495     0.808625   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.405063              0.600000               0.704762   
recall               0.711111              0.568966               0.654867   
f1-score             0.516129              0.584071               0.678899   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.847826         0.666667  0.751969    0.771013   
recall               0.735849         0.754717  0.751969    0.670441   
f1-score             0.787879         0.707965  0.751969    0.673547   
support             53.000000       106.000000  0.751969  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.776524  
recall         0.751969  
f1-score       0.754131  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s5,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7506561679790026,0.8096845391572322,0.6219976492113568,0.7836981349670972,0.7506561679790026,0.6524038948547534,0.745391900569644,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          1.000000      0.896296     0.798077   
recall               0.111111          0.536585      0.889706     0.825871   
f1-score             0.200000          0.698413      0.892989     0.811736   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.595238              0.807692               0.783784   
recall               0.555556              0.362069               0.769912   
f1-score             0.574713              0.500000               0.776786   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.875000         0.531073  0.750656    0.809685   
recall               0.660377         0.886792  0.750656    0.621998   
f1-score             0.752688         0.664311  0.750656    0.652404   
support             53.000000       106.000000  0.750656  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.783698  
recall         0.750656  
f1-score       0.745392  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s5,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7559055118110236,0.6859702468422059,0.6402860361578461,0.7531045863173471,0.7559055118110236,0.6581270738641702,0.7502901300990963,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.909091      0.920863     0.717949   
recall                    0.0          0.731707      0.941176     0.835821   
f1-score                  0.0          0.810811      0.930909     0.772414   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.857143              0.545455               0.732673   
recall               0.666667              0.517241               0.654867   
f1-score             0.750000              0.530973               0.691589   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.829268         0.661290  0.755906    0.685970   
recall               0.641509         0.773585  0.755906    0.640286   
f1-score             0.723404         0.713043  0.755906    0.658127   
support             53.000000       106.000000  0.755906  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.753105  
recall         0.755906  
f1-score       0.750290  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s6,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7152230971128609,0.6200698185386337,0.6238604649889354,0.7207048685978173,0.7152230971128609,0.6195028611073657,0.7155694526361539,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.812500      0.933333     0.763033   
recall                    0.0          0.951220      0.823529     0.800995   
f1-score                  0.0          0.876404      0.875000     0.781553   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.692308              0.322581               0.642857   
recall               0.600000              0.344828               0.716814   
f1-score             0.642857              0.333333               0.677824   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.694915         0.719101  0.715223    0.620070   
recall               0.773585         0.603774  0.715223    0.623860   
f1-score             0.732143         0.656410  0.715223    0.619503   
support             53.000000       106.000000  0.715223  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.720705  
recall         0.715223  
f1-score       0.715569  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s6,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.6614173228346457,0.6948184646057762,0.5898145885423978,0.722674823025363,0.6614173228346457,0.5717030788841677,0.6630324531739499,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.686275      0.898305     0.831325   
recall               0.111111          0.853659      0.779412     0.686567   
f1-score             0.200000          0.760870      0.834646     0.752044   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.312500              0.777778               0.539877   
recall               0.555556              0.241379               0.778761   
f1-score             0.400000              0.368421               0.637681   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.450549         0.756757  0.661417    0.694818   
recall               0.773585         0.528302  0.661417    0.589815   
f1-score             0.569444         0.622222  0.661417    0.571703   
support             53.000000       106.000000  0.661417  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.722675  
recall         0.661417  
f1-score       0.663032  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s6,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7309711286089239,0.6759441056854314,0.6718859782462407,0.7388433301827941,0.7309711286089239,0.6684088919610225,0.7291704056679904,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.272727          0.738095      0.958678     0.702479   
recall               0.333333          0.756098      0.852941     0.845771   
f1-score             0.300000          0.746988      0.902724     0.767494   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.633333              0.666667               0.732558   
recall               0.844444              0.517241               0.557522   
f1-score             0.723810              0.582524               0.633166   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.705882         0.673077  0.730971    0.675944   
recall               0.679245         0.660377  0.730971    0.671886   
f1-score             0.692308         0.666667  0.730971    0.668409   
support             53.000000       106.000000  0.730971  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.738843  
recall         0.730971  
f1-score       0.729170  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s6,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7454068241469817,0.701594815770322,0.6628131415854275,0.7554762364039829,0.7454068241469817,0.6645378126470227,0.746128684740171,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.500000          0.825000      0.917293     0.857923   
recall               0.111111          0.804878      0.897059     0.781095   
f1-score             0.181818          0.814815      0.907063     0.817708   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.823529              0.409091               0.701754   
recall               0.622222              0.465517               0.707965   
f1-score             0.708861              0.435484               0.704846   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.671429         0.608333  0.745407    0.701595   
recall               0.886792         0.688679  0.745407    0.662813   
f1-score             0.764228         0.646018  0.745407    0.664538   
support             53.000000       106.000000  0.745407  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.755476  
recall         0.745407  
f1-score       0.746129  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s6,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7480314960629921,0.6763868817241856,0.6416980705912245,0.760431434029926,0.7480314960629921,0.6485029722725464,0.7444165241648444,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          1.000000      0.783951     0.888889   
recall                    0.0          0.707317      0.933824     0.756219   
f1-score                  0.0          0.828571      0.852349     0.817204   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.634615              0.489362               0.716981   
recall               0.733333              0.396552               0.672566   
f1-score             0.680412              0.438095               0.694064   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.973684         0.600000  0.748031    0.676387   
recall               0.698113         0.877358  0.748031    0.641698   
f1-score             0.813187         0.712644  0.748031    0.648503   
support             53.000000       106.000000  0.748031  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.760431  
recall         0.748031  
f1-score       0.744417  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s6,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7572178477690289,0.6829504190503646,0.6673093434609595,0.7573726323824405,0.7572178477690289,0.6702800469109602,0.751125367748927,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision                 0.0          0.921053      0.936508     0.789954   
recall                    0.0          0.853659      0.867647     0.860697   
f1-score                  0.0          0.886076      0.900763     0.823810   
support                   9.0         41.000000    136.000000   201.000000   
Test                      9.0         41.000000    136.000000   201.000000   
Train                     1.0          5.000000     15.000000    22.000000   
Total                    10.0         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.860465              0.491228               0.679012   
recall               0.822222              0.482759               0.486726   
f1-score             0.840909              0.486957               0.567010   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.875000         0.593333  0.757218    0.682950   
recall               0.792453         0.839623  0.757218    0.667309   
f1-score             0.831683         0.695312  0.757218    0.670280   
support             53.000000       106.000000  0.757218  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.757373  
recall         0.757218  
f1-score       0.751125  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s7,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['com', 'tow', 'lc', 'sw', 'stem'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.699475065616798,0.6419915515085427,0.6081995446765421,0.7153010501236703,0.699475065616798,0.6002883124910662,0.6980423940224054,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.500000          0.634146      1.000000     0.781095   
recall               0.111111          0.634146      0.882353     0.781095   
f1-score             0.181818          0.634146      0.937500     0.781095   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.634615              0.531250               0.642857   
recall               0.733333              0.293103               0.557522   
f1-score             0.680412              0.377778               0.597156   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.418367         0.635593  0.699475    0.641992   
recall               0.773585         0.707547  0.699475    0.608200   
f1-score             0.543046         0.669643  0.699475    0.600288   
support             53.000000       106.000000  0.699475  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.715301  
recall         0.699475  
f1-score       0.698042  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s7,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['com', 'tow', 'lc', 'sw', 'stem'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.6443569553805775,0.6520767276327691,0.5775701224736001,0.697756127643584,0.6443569553805775,0.5542536029773664,0.651535676946885,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.548387      0.990566     0.752525   
recall               0.111111          0.829268      0.772059     0.741294   
f1-score             0.200000          0.660194      0.867769     0.746867   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.276596              0.472222               0.617978   
recall               0.577778              0.293103               0.486726   
f1-score             0.374101              0.361702               0.544554   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.447917         0.762500  0.644357    0.652077   
recall               0.811321         0.575472  0.644357    0.577570   
f1-score             0.577181         0.655914  0.644357    0.554254   
support             53.000000       106.000000  0.644357  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.697756  
recall         0.644357  
f1-score       0.651536  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s7,Bag-of-words,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['com', 'tow', 'lc', 'sw', 'stem'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7545931758530183,0.7133801264137305,0.7014340713998277,0.7897732676436013,0.7545931758530183,0.6891617562258304,0.7577942610153292,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.250000          0.897436      0.950355     0.793814   
recall               0.333333          0.853659      0.985294     0.766169   
f1-score             0.285714          0.875000      0.967509     0.779747   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.519481              0.452055               0.898551   
recall               0.888889              0.568966               0.548673   
f1-score             0.655738              0.503817               0.681319   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            1.000000         0.658730  0.754593    0.713380   
recall               0.584906         0.783019  0.754593    0.701434   
f1-score             0.738095         0.715517  0.754593    0.689162   
support             53.000000       106.000000  0.754593  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.789773  
recall         0.754593  
f1-score       0.757794  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
MaxEnt,s7,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['com', 'tow', 'lc', 'sw', 'stem'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7690288713910761,0.7043477395936983,0.7113953726083563,0.7886900133002627,0.7690288713910761,0.7005783127682905,0.7726524662793057,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            0.166667          0.950000      0.984375     0.917160   
recall               0.222222          0.926829      0.926471     0.771144   
f1-score             0.190476          0.938272      0.954545     0.837838   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.925000              0.547619               0.629630   
recall               0.822222              0.396552               0.752212   
f1-score             0.870588              0.460000               0.685484   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.592593         0.626087  0.769029    0.704348   
recall               0.905660         0.679245  0.769029    0.711395   
f1-score             0.716418         0.651584  0.769029    0.700578   
support             53.000000       106.000000  0.769029  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.788690  
recall         0.769029  
f1-score       0.772652  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
SVM,s7,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['com', 'tow', 'lc', 'sw', 'stem'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7624671916010499,0.798444170666393,0.6519683845330142,0.7847871139865891,0.7624671916010499,0.6694593343211817,0.7571971893877948,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          1.000000      1.000000     0.830769   
recall               0.111111          0.658537      0.911765     0.805970   
f1-score             0.200000          0.794118      0.953846     0.818182   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.729730              0.703704               0.621795   
recall               0.600000              0.327586               0.858407   
f1-score             0.658537              0.447059               0.721190   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.692308         0.607692  0.762467    0.798444   
recall               0.849057         0.745283  0.762467    0.651968   
f1-score             0.762712         0.669492  0.762467    0.669459   
support             53.000000       106.000000  0.762467  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.784787  
recall         0.762467  
f1-score       0.757197  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
Naive-Bayes,s7,TF-IDF,"[['lib', 'tow', 'jk', 'scw', 'lc', 'sw', 'stem'], ['pac', 'tow', 'jk'], ['c', 'tow', 'jk', 'scw', 'lc'], ['com', 'tow', 'lc', 'sw', 'stem'], ['pm', 'tow', 'jk', 'scw', 'lc', 'sw'], ['pv', 'tow', 'jk', 'scw', 'lc']]",0.7821522309711286,0.8068401030994541,0.6983096145806429,0.788902184818004,0.7821522309711286,0.7105026045180773,0.7780182686406878,84,762,"           basicutils-6.9.126  graphviz-6.9.256  kitfox-6.9.6  log-6.9.380  \
precision            1.000000          0.878049      0.975610     0.735931   
recall               0.111111          0.878049      0.882353     0.845771   
f1-score             0.200000          0.878049      0.926641     0.787037   
support              9.000000         41.000000    136.000000   201.000000   
Test                 9.000000         41.000000    136.000000   201.000000   
Train                1.000000          5.000000     15.000000    22.000000   
Total               10.000000         46.000000    151.000000   223.000000   

           logskeleton-6.9.91  prom-contexts-6.9.56  prom-framework-6.9.97  \
precision            0.775000              0.620000               0.768421   
recall               0.688889              0.534483               0.646018   
f1-score             0.729412              0.574074               0.701923   
support             45.000000             58.000000             113.000000   
Test                45.000000             58.000000             113.000000   
Train                5.000000              6.000000              12.000000   
Total               50.000000             64.000000             125.000000   

           prom-models-6.9.32  widgets-6.9.234  accuracy   macro avg  \
precision            0.793103         0.715447  0.782152    0.806840   
recall               0.867925         0.830189  0.782152    0.698310   
f1-score             0.828829         0.768559  0.782152    0.710503   
support             53.000000       106.000000  0.782152  762.000000   
Test                53.000000       106.000000       NaN         NaN   
Train                6.000000        12.000000       NaN         NaN   
Total               59.000000       118.000000       NaN         NaN   

           weighted avg  
precision      0.788902  
recall         0.782152  
f1-score       0.778018  
support      762.000000  
Test                NaN  
Train               NaN  
Total               NaN  "
