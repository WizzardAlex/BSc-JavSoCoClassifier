{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Laoa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2021-05-03 10:54:48,930\tINFO services.py:1173 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "# Imports and scripts\n",
    "#import pandas as pd\n",
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pathmagic\n",
    "%matplotlib inline\n",
    "with pathmagic.context():\n",
    "    import Preprocess as Prep\n",
    "    import RelativePaths as RP\n",
    "    import Evaluation as Eva\n",
    "    import GatherData as Gather\n",
    "    import Graphs\n",
    "    import Utils\n",
    "import ray\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "system = 'jabref'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File containing settings\n",
    "path_to_yaml = '../config.yaml'\n",
    "config = Utils.read_yaml_file(path_to_yaml)\n",
    "\n",
    "files = config['file locations'][system]\n",
    "preprocess_settings = config['preprocess settings list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set file_locations which will be relative to computer in use\n",
    "from pathlib import Path\n",
    "raw_data_csv = str(Path.cwd().parent / files['raw data'])\n",
    "system_folder = str(Path.cwd().parent / files['system folder'])\n",
    "tmp_csv = str(Path.cwd().parent / files['tmp data'])\n",
    "table_file = str(Path.cwd().parent / files['preprocess comparisons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gather.gather_architectural_concerns_data(system_folder, raw_data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv(raw_data_csv)\n",
    "y_labels = dataset_df.Label.unique()\n",
    "x_quantity = [len(dataset_df.loc[dataset_df['Label']==label]) for label in y_labels]\n",
    "tmp_df = pd.DataFrame({\n",
    "    'Labels' : y_labels,\n",
    "    'Quantity' : x_quantity\n",
    "})\n",
    "tmp_df = tmp_df.sort_values(by=['Quantity'])\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.barh(y=tmp_df.Labels, width=tmp_df.Quantity)\n",
    "for i, v in enumerate(tmp_df.Quantity):\n",
    "    plt.text(v, i, str(v), color='black', fontweight='bold', ha='left', va='center')\n",
    "\n",
    "plt.xlabel('Quantities')\n",
    "plt.ylabel('Labels')\n",
    "plt.title('File distribution of the software architectural concerns for ' + system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_columns = [\n",
    "    'classifier',\n",
    "    'setting_id',\n",
    "    'settings', \n",
    "    'accuracy', \n",
    "    'macro_precision', \n",
    "    'macro_recall', \n",
    "    'train_size', \n",
    "    'test_size', \n",
    "    'report_table' \n",
    "]\n",
    "main_table = pd.DataFrame(columns=df_columns)\n",
    "test_size=0.9\n",
    "fold_quantity = 100\n",
    "\n",
    "for setting_id, setting in preprocess_settings.items():\n",
    "    Prep.preprocess_settings(setting, raw_data_csv, tmp_csv)\n",
    "    tmp_df = pd.read_csv(tmp_csv)\n",
    "\n",
    "    # Remove GLOBALS and CLI from the dataset\n",
    "    df_sliced = Utils.remove_concerns_under_quantity_threshold(tmp_df)\n",
    "\n",
    "    feature_representation = CountVectorizer()\n",
    "    confusion_list = []\n",
    "\n",
    "    # Train and gather evaluation metrics\n",
    "    evaluate = Eva.Evaluation(df_sliced, feature_representation, test_size, fold_quantity, 10)\n",
    "    classifier_max_ent , metrics_max_ent = evaluate.evaluate_MaxEnt()\n",
    "    classifier_svm , metrics_svm = evaluate.evaluate_SVM()\n",
    "    classifier_naive, metrics_naive = evaluate.evaluate_Naive_Bayes()\n",
    "    \n",
    "    \n",
    "    row = Utils.make_dataframe_row(metrics_max_ent, setting, setting_id)\n",
    "    main_table = main_table.append(row, ignore_index=True)\n",
    "\n",
    "    row = Utils.make_dataframe_row(metrics_svm, setting, setting_id)\n",
    "    main_table = main_table.append(row, ignore_index=True)\n",
    "    \n",
    "    row = Utils.make_dataframe_row(metrics_naive, setting, setting_id)\n",
    "    main_table = main_table.append(row, ignore_index=True)\n",
    "\n",
    "main_table.to_csv(table_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_table.sort_values(by='accuracy',ascending=[False])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "juiceBox",
   "language": "python",
   "name": "juicebox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
